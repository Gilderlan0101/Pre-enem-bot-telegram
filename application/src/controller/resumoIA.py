import logging
import os

from dotenv import load_dotenv
from openai import OpenAI
from telegram.ext import ContextTypes

from application.src.controller.command_limiter import CommandLimiter
from application.src.controller.premium import SubscribePremium
from application.src.models.user import get_user_data
from application.src.utils.db_tools import incrementar_coluna
from application.src.utils.get_info_user import with_user_info
from config import request_plan_free

# Carregando variaves de ambiente
load_dotenv()


def gerar_resumo_com_fallback(username, assunto):
    prompt = (
        f'Ol√°, meu nome √© {username}. Preciso de um resumo claro e direto sobre o tema "{assunto}".\n'
        'Explique como se fosse para um estudante do ensino m√©dio revisando para o ENEM.\n'
        'Use **somente portugu√™s**, com no m√°ximo 10 linhas, linguagem acess√≠vel e objetiva.\n'
        'Evite termos t√©cnicos dif√≠ceis. N√£o escreva absolutamente nada em ingl√™s.'
    )

    client = OpenAI(
        base_url='https://openrouter.ai/api/v1',
        api_key=os.getenv('API_KEY_IA'),
        timeout=20,
        project='PreEnemBot',
    )

    modelos = ['openai/codex-mini', 'openai/gpt-3.5-turbo']

    for modelo in modelos:
        try:
            response = client.chat.completions.create(
                model=modelo,
                messages=[{'role': 'user', 'content': prompt}],
                max_tokens=500,
            )

            content = getattr(
                response.choices[0].message, 'content', ''
            ).strip()
            if content:
                print(f'‚úÖ Modelo usado: {modelo}')
                return content, None

        except Exception as e:
            logging.warning(f"[Fallback IA] Modelo '{modelo}' falhou: {e}")

    return (
        '‚ö†Ô∏è N√£o foi poss√≠vel gerar um resumo no momento. Tente novamente mais tarde.',
        None,
    )


@with_user_info
async def resum_of_IA(update, context, username, user_id=None, assunto=None):
    try:
        if not user_id:
            return '‚ùå Erro: usu√°rio n√£o identificado.', None

        # ‚úÖ Verificar se o usu√°rio atingiu o limite
        limitador = CommandLimiter(user_id)
        liberado = limitador.user_quota_resum
        if not liberado:
            await SubscribePremium().subscribe(update=update, context=context)
            return

        # ‚úÖ Verifica o plano (extra seguran√ßa)
        user_data = get_user_data(user_id=user_id)
        plano = user_data.get('plan', '')

        if plano != 'Gratuito':
            return request_plan_free['message_plan'], None

        if not assunto:
            return '‚ùå Assunto n√£o especificado.', None

        # ‚úÖ Gera√ß√£o com fallback
        content, erro = gerar_resumo_com_fallback(username, assunto)
        if erro:
            return content, erro

        # ‚úÖ Atualizar contagem
        incrementar_coluna(
            nome_tabela='usuarios',
            coluna='quantidade_resumos',
            user_id=user_id,
            incremento=1,
        )

        return content, None

    except Exception as e:
        logging.error(f'[Erro em resum_of_IA]: {e}')
        return (
            '‚ùå Erro interno ao gerar o resumo. Tente novamente mais tarde.',
            None,
        )


def ResponseQuiz(context: ContextTypes, resposta_usuario=None, UserID=None):
    try:
        if not UserID:
            return '‚ùå Erro: usu√°rio n√£o identificado.', None

        user_data = get_user_data(user_id=UserID)
        plano = user_data.get('plan', '')

        if plano != 'Gratuito':
            return request_plan_free['message_plan'], None

        client = OpenAI(
            base_url='https://openrouter.ai/api/v1',
            api_key=os.getenv('API_KEY_IA'),
            timeout=20,
            project='PreEnemBot',
        )

        # Recuperar dados da pergunta
        pergunta = context.user_data.get('pergunta')
        resposta_correta = context.user_data.get('quiz_resposta')

        if not pergunta or not resposta_correta:
            return (
                '‚ùå N√£o foi poss√≠vel recuperar a quest√£o enviada anteriormente.',
                None,
            )

        if not resposta_usuario:
            return (
                '‚ùå Voc√™ precisa informar sua resposta (ex: A, B, C ou D).',
                None,
            )

        # üß† Novo prompt: IA explica apenas a alternativa correta
        prompt = (
            f'Voc√™ √© um professor explicando a quest√£o de um simulado do ENEM.\n\n'
            f"üî∏ Pergunta: {pergunta['pergunta']}\n"
            f'üî∏ Op√ß√µes:\n'
            f"   A) {pergunta['opcoes'][0]}\n"
            f"   B) {pergunta['opcoes'][1]}\n"
            f"   C) {pergunta['opcoes'][2]}\n"
            f"   D) {pergunta['opcoes'][3]}\n\n"
            f'‚úÖ A resposta correta √©: {resposta_correta}\n'
            f'üìö Explique por que essa alternativa est√° certa de forma clara, direta e educativa para um estudante de ensino m√©dio.'
        )

        response = client.chat.completions.create(
            model='openai/gpt-3.5-turbo',
            messages=[{'role': 'user', 'content': prompt}],
            max_tokens=600,
        )

        content = getattr(response.choices[0].message, 'content', '').strip()
        if not content:
            return (
                '‚ö†Ô∏è N√£o foi poss√≠vel gerar uma explica√ß√£o agora. Tente novamente em breve.',
                None,
            )

        return content, None

    except Exception as e:
        logging.error(f'[Erro em ResponseQuiz]: {e}')
        return (
            '‚ùå Erro interno ao gerar o feedback. Tente novamente mais tarde.',
            None,
        )
